{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BioCAS 2023 Grand Challenge**\n",
    "\n",
    "### Team\n",
    "\n",
    "This project is ...\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Working Flow <a id=\"list_of_content\"></a>\n",
    "\n",
    "## 1. [Initiate Framework](#initialization)\n",
    "## 2. [Generate Dataloaders](#dataloaders)\n",
    "## 3. [Pretrain SupCon Model](#supcon)\n",
    "## 4. [Evaluate SupCon Model](#tsen)\n",
    "## 5. [FineTune Overall Model](#finetune)\n",
    "## 6. [Evaluate Fintunned Model](#evaluate)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Initiate Framework <a id=\"initialization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import snntorch.functional as SF\n",
    "\n",
    "from collections import Counter\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "import src.models as mdl\n",
    "import src.data.dataset as ds\n",
    "import src.data.dataloader as dl\n",
    "import src.utils.visualizing as vs\n",
    "\n",
    "from src.train import train_supcon, valid_supcon, train_model\n",
    "from src.test import test_supcon, test_model\n",
    "from src.utils.supcontrast import TwoCropTransform, SupConLoss\n",
    "from src.utils.supcontrast import adjust_learning_rate, set_optimizer, save_model\n",
    "\n",
    "import importlib\n",
    "importlib.reload(mdl)\n",
    "importlib.reload(ds)\n",
    "importlib.reload(dl)\n",
    "importlib.reload(vs)\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Globals --------------------#\n",
    "# Device Config\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {DEVICE} on {torch.cuda.get_device_name(0)} :D \")\n",
    "\n",
    "# Feature Config\n",
    "MAX_LENGTH = 3.0\n",
    "SR = 8000\n",
    "HOP_LENGTH = 128\n",
    "MAX_LENGTH_SAMPLES = int(MAX_LENGTH * SR / HOP_LENGTH)\n",
    "INPUT_X_DIM = int(MAX_LENGTH * SR / HOP_LENGTH)\n",
    "N_F_BIN = 64\n",
    "N_FFT = 512\n",
    "FEATURE = \"mfcc\"\n",
    "\n",
    "# Log Config\n",
    "formatter = logging.Formatter(\"%(asctime)s:%(levelname)s:%(name)s:%(message)s\")\n",
    "\n",
    "# Warning Config\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Define customized Argparse --------------------#\n",
    "class Argparse:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def print_args(self):\n",
    "        argparse_dict = vars(self)\n",
    "        for key, value in argparse_dict.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "opt = Argparse(\n",
    "    # Dataset Config\n",
    "    task_in = \"Task_12\", data_path = \"SPRSound/\", \n",
    "    batch_size = 32, val_percent = 0.2,\n",
    "    \n",
    "    # Model Config\n",
    "    model = \"resnet18\", embedding_size = 512, \n",
    "    head = \"linear\", ckpt = \"ckpt_epoch_200.pth\", \n",
    "\n",
    "    # Train Config\n",
    "    print_freq = 50, save_freq = 50, epochs = 100, \n",
    "\n",
    "    # Optim Config\n",
    "    optimizer = \"SGD\",\n",
    "    learning_rate = 0.001, momentum = 0.9,\n",
    "    lr_decay_rate = 0.1, lr_decay_epochs = \"70,80,90\",\n",
    "    weight_decay = 1e-4, dropout = 0.25,\n",
    "\n",
    "    # SupCon Config\n",
    "    temperature = 0.1, method = \"SupCon\",\n",
    "\n",
    "    # Other Config\n",
    "    cosine = True, warm = False, verbose = False,\n",
    ")\n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(\",\")\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.batch_size > 256:\n",
    "    opt.warm = True\n",
    "if opt.warm:\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "\n",
    "# set the path according to the environment\n",
    "opt.model_path = \"./ckpts/PreTrain-Models/{}\".format(opt.task_in)\n",
    "opt.model_name = \"{}_{}{}_{}{}_hop{}_{}_lr{}_temp{}_drop{}_val{}\".format(\n",
    "    opt.model, \n",
    "    FEATURE, \n",
    "    N_F_BIN, \n",
    "    opt.head,\n",
    "    opt.embedding_size,\n",
    "    HOP_LENGTH, \n",
    "    opt.optimizer,\n",
    "    opt.learning_rate,\n",
    "    opt.temperature,\n",
    "    opt.dropout,\n",
    "    opt.val_percent,\n",
    ")\n",
    "opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
    "if not os.path.isdir(opt.save_folder):\n",
    "    os.makedirs(opt.save_folder)\n",
    "\n",
    "# Print all arguments\n",
    "opt.print_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- User-defined functions --------------------#\n",
    "def setupLogger(name, logPath, level=logging.INFO):\n",
    "    handler = logging.FileHandler(logPath)\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "log_path = \"logs/BioCAS-Notes.logs\"\n",
    "if not os.path.exists(log_path):\n",
    "    open(log_path, \"a\").close()\n",
    "logger = setupLogger(\"ResultsLogger\", log_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Back to List of Content](#list_of_content)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Generate Dataloaders <a id=\"dataloaders\"></a>\n",
    "\n",
    "By providing the input task ```task_in``` and PATH of data ```data_path```, the three ***Datasets*** and four ***Dataloaders*** are generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_in = opt.task_in\n",
    "data_path = opt.data_path\n",
    "\n",
    "data_dict={\n",
    "    \"train\":[\n",
    "        os.path.join(data_path, \"train_wav\"), \n",
    "        os.path.join(data_path, \"train_json\")\n",
    "    ],\n",
    "    \"intra_test\":[\n",
    "        os.path.join(data_path, \"test_wav\"), \n",
    "        os.path.join(data_path, \"test_json/intra_test_json\")\n",
    "    ],\n",
    "    \"inter_test\":[\n",
    "        os.path.join(data_path, \"test_wav\"),\n",
    "        os.path.join(data_path, \"test_json/inter_test_json\")\n",
    "    ],\n",
    "}\n",
    "\n",
    "main_task = int(task_in[-2])\n",
    "sub_task = int(task_in[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset, intra_testDataset, inter_testDataset = ds.genDatasets(\n",
    "    task=main_task, \n",
    "    data_dict=data_dict,\n",
    "    resample=None,\n",
    "    feature=FEATURE,\n",
    "    pre_emph=False,\n",
    "    pos_norm=\"zscore\",\n",
    "    n_mfcc=N_F_BIN,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_fft=N_FFT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare trainValLoader for SupCon pretraining\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size=(N_F_BIN, MAX_LENGTH_SAMPLES), padding=0, pad_if_needed=True),\n",
    "])\n",
    "\n",
    "supcon_loader = dl.trainValLoader(\n",
    "    trainDataset,\n",
    "    sub_task,\n",
    "    valid_size=opt.val_percent,\n",
    "    batch_size=opt.batch_size,\n",
    "    collate_fn=lambda batch: dl.supcon_collate(\n",
    "        batch, task_in, sub_task, transform=TwoCropTransform(train_transform)\n",
    "    ),\n",
    "    train_sampler=\"balanced\",\n",
    "    val_sampler=\"balanced\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-contrastive dataloaders\n",
    "dataloader = dl.trainValLoader(\n",
    "    trainDataset,\n",
    "    sub_task,\n",
    "    valid_size=opt.val_percent,\n",
    "    batch_size=opt.batch_size,\n",
    "    collate_fn=lambda batch: dl.custom_collate(\n",
    "        batch, MAX_LENGTH_SAMPLES, task_in, sub_task\n",
    "    ),\n",
    "    train_sampler=\"balanced\",\n",
    "    val_sampler=\"balanced\",\n",
    ")\n",
    "\n",
    "print(\"\\n\\nGenerating Dataloader for Intra Dataset...\")\n",
    "intra_testloader = dl.testLoader(\n",
    "    intra_testDataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    collate_fn=lambda batch: dl.custom_collate(\n",
    "        batch, MAX_LENGTH_SAMPLES, task_in, sub_task\n",
    "    ),\n",
    "    shuffle_in=False,\n",
    ")\n",
    "\n",
    "print(\"\\nGenerating Dataloader for Inter Dataset...\")\n",
    "inter_testloader = dl.testLoader(\n",
    "    inter_testDataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    collate_fn=lambda batch: dl.custom_collate(\n",
    "        batch, MAX_LENGTH_SAMPLES, task_in, sub_task\n",
    "    ),\n",
    "    shuffle_in=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, label, info) in enumerate(dataloader[\"train\"]):        \n",
    "    if batch_idx <= 5:\n",
    "        print(batch_idx, data.size(), info.size(), label.cpu().numpy().shape, Counter(label.cpu().numpy().flatten()))\n",
    "    else: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(dl.classes[task_in])\n",
    "print(\"The number of classes for \"+ task_in + f\" is {num_classes}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Back to List of Content](#list_of_content)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Pretrain SupCon Model <a id=\"supcon\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model, criterion and optimizer\n",
    "model = mdl.SupConResNet(\n",
    "    name=opt.model,\n",
    "    head=opt.head, \n",
    "    feat_dim=opt.embedding_size,\n",
    "    dropout=opt.dropout,\n",
    ")\n",
    "criterion = SupConLoss(temperature=opt.temperature)\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model.encoder = nn.DataParallel(model.encoder)\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "optimizer = set_optimizer(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training routine\n",
    "best_loss = 0\n",
    "best_epoch = 1\n",
    "hist_loss = []\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    adjust_learning_rate(opt, optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    time1 = time.time()\n",
    "    train_loss = train_supcon(supcon_loader[\"train\"], model, criterion, optimizer, epoch, opt)\n",
    "    hist_loss.append(train_loss)\n",
    "    valid_loss = valid_supcon(supcon_loader[\"val\"], model, criterion, opt)\n",
    "    hist_loss.append(1/valid_loss)\n",
    "    time2 = time.time()\n",
    "    print(\"epoch {}, total time {:.2f}, train loss: {:.2f}, valid loss: {:.2f}\".format(epoch, time2 - time1, train_loss, 1/valid_loss))\n",
    "\n",
    "    if valid_loss > best_loss:\n",
    "        best_loss = valid_loss\n",
    "        best_model = model\n",
    "        best_optimizer = optimizer\n",
    "        best_epoch = epoch\n",
    "\n",
    "    if epoch % opt.save_freq == 0:\n",
    "        save_file = os.path.join(\n",
    "            opt.save_folder, \"ckpt_epoch_{epoch}.pth\".format(epoch=epoch))\n",
    "        save_model(model, optimizer, opt, epoch, save_file)\n",
    "\n",
    "# save the best model\n",
    "save_file = os.path.join(opt.save_folder, \"best.pth\")\n",
    "save_model(best_model, best_optimizer, opt, opt.epochs, save_file)\n",
    "\n",
    "# log results\n",
    "log_msg = (\n",
    "    f\"PreTrain - Model: {opt.model}_{FEATURE}{N_F_BIN}, Task: {opt.task_in}. Epoch: {opt.epochs}, \"\n",
    "    f\"Last train loss: {train_loss:>0.2f}, \"\n",
    "    f\"Best valid loss: {1/best_loss:>0.2f} at epoch {best_epoch}, \"\n",
    "    f\"Method: {opt.method}. Temperature: {opt.temperature:>0.2f}, \"\n",
    "    f\"Embedding size: {opt.head}{opt.embedding_size}, \"\n",
    "    f\"Hop length: {HOP_LENGTH}, Optimizer: {opt.optimizer}, \"\n",
    "    f\"Learning rate: {opt.learning_rate}, Dropout: {opt.dropout} \"\n",
    ")\n",
    "logger.info(log_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss during training\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(hist_loss[0::2], label=\"train_loss\")\n",
    "plt.plot(hist_loss[1::2], label=\"validation_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Back to List of Content](#list_of_content)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Evaluate SupCon Model <a id=\"tsen\"></a>\n",
    "\n",
    "Visualizing via T-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SupCon model\n",
    "model_path = os.path.join(opt.save_folder, opt.ckpt)\n",
    "model_info = torch.load(model_path)\n",
    "SupCon = mdl.SupConResNet(\n",
    "    name=opt.model, \n",
    "    head=opt.head, \n",
    "    feat_dim=opt.embedding_size,\n",
    "    dropout=opt.dropout,\n",
    ").to(DEVICE)\n",
    "SupCon.load_state_dict(model_info[\"model\"])\n",
    "SupCon.eval()\n",
    "print(\"SupCon model is switched to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding array\n",
    "inputloader = dataloader[\"train\"]\n",
    "targets = []\n",
    "embeddings = torch.zeros((0, opt.embedding_size), dtype=torch.float32)\n",
    "for data, label, _ in inputloader:\n",
    "    data = data.to(DEVICE)\n",
    "    embedding = SupCon(data)\n",
    "    targets.extend(label.detach().cpu().tolist())\n",
    "    embeddings = torch.cat((embeddings, embedding.detach().cpu()), dim=0)\n",
    "\n",
    "X = np.array(embeddings)\n",
    "y = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne1 = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
    "X_embedded1 = tsne1.fit_transform(X)\n",
    "\n",
    "tsne2 = TSNE(n_components=2, perplexity=50, learning_rate=500, random_state=42)\n",
    "X_embedded2 = tsne2.fit_transform(X)\n",
    "\n",
    "# Visualize the t-SNE embeddings\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_embedded1[:, 0], X_embedded1[:, 1], c=y, cmap=\"jet\")\n",
    "plt.title(\"t-SNE with perplexity=30,\\n learning_rate=200\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_embedded2[:, 0], X_embedded2[:, 1], c=y, cmap=\"jet\")\n",
    "plt.title(\"t-SNE with perplexity=50,\\n learning_rate=500\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Back to List of Content](#list_of_content)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. FineTune Overall Model <a id=\"finetune\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model):\n",
    "    if model == \"SupCon\":\n",
    "        PRS_model = mdl.PRS_classifier(opt, num_classes=num_classes, pretrain=True).to(DEVICE)\n",
    "\n",
    "        for param in PRS_model.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in PRS_model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        spike = False\n",
    "        return PRS_model, loss_fn, spike\n",
    "    \n",
    "    elif model == \"ResNet\":\n",
    "        PRS_classifier = mdl.simpleResNet(\n",
    "            num_classes=num_classes,\n",
    "        ).to(DEVICE)\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        spike = False\n",
    "        return PRS_classifier, loss_fn, spike\n",
    "    \n",
    "    elif model == \"CNN\":\n",
    "        PRS_classifier = mdl.leanCNN(\n",
    "            num_class=num_classes,\n",
    "            input_fdim=N_F_BIN,\n",
    "            input_tdim=INPUT_X_DIM,\n",
    "        ).to(DEVICE)\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        spike = False\n",
    "        return PRS_classifier, loss_fn, spike\n",
    "    \n",
    "    elif model == \"SNN\":\n",
    "        PRS_classifier = mdl.customSNet(\n",
    "            num_steps=10, beta=0.5, num_class=num_classes\n",
    "        ).to(DEVICE)\n",
    "        loss_fn = SF.loss.ce_count_loss(False, False)\n",
    "        spike = True\n",
    "        return PRS_classifier, loss_fn, spike\n",
    "    \n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"No such model, please select within (SupCon, ResNet)\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(model_name, strategy, epoch_num=10, num_iters=2, save_model=True):\n",
    "\n",
    "    best_result = {}\n",
    "    for item in strategy:\n",
    "        best_result[item] = 0\n",
    "    best_dict = {}\n",
    "\n",
    "    print('Perform', model_name, 'Model Architecture\\n')\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        print('\\nModel iter: {}/{}...\\n'.format(i+1, num_iters))\n",
    "        PRS_classifier, loss_fn, spike = get_model(model_name)\n",
    "        print('Model Reset')\n",
    "        \n",
    "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, PRS_classifier.parameters()), lr=0.001, weight_decay=0.0001) \n",
    "\n",
    "        best_iter_dict = train_model(\n",
    "            device=DEVICE,\n",
    "            task=task_in,\n",
    "            dataloader=dataloader, \n",
    "            model=PRS_classifier, \n",
    "            criterion=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            n_epochs=epoch_num,\n",
    "            print_every=1,\n",
    "            verbose=True,\n",
    "            plot_results=True, \n",
    "            validation=True,\n",
    "            save_ckpt=False,\n",
    "            spike=spike,\n",
    "            model_name=model_name,\n",
    "            strategy=strategy,\n",
    "        )\n",
    "        ### End of model and task customization <<<<<\n",
    "        print('')\n",
    "\n",
    "        for item in strategy:\n",
    "            test_classifier,_,spike = get_model(model_name)\n",
    "            test_classifier.load_state_dict(best_iter_dict[item][\"model_state_dict\"])\n",
    "            test_classifier.eval()\n",
    "\n",
    "            inter_score,*_ = test_model(\n",
    "                device=DEVICE,\n",
    "                task=main_task,\n",
    "                dataloader=inter_testloader,\n",
    "                trained_model=test_classifier,\n",
    "                spike=spike\n",
    "            )\n",
    "            intra_score,*_ = test_model(\n",
    "                device=DEVICE,\n",
    "                task=main_task,\n",
    "                dataloader=intra_testloader,\n",
    "                trained_model=test_classifier,\n",
    "                spike=spike\n",
    "            )\n",
    "            test_score = (inter_score + intra_score)/2\n",
    "\n",
    "            print('Iter best test score under', item, 'is:', test_score)\n",
    "            \n",
    "            if test_score > best_result[item]:\n",
    "                best_result[item] = test_score\n",
    "                best_dict[item] = best_iter_dict[item]\n",
    "            \n",
    "            epoch,_,_,score, acc, loss = best_iter_dict[item].values()\n",
    "            valloss = 1/loss\n",
    "            log_msg = (\n",
    "                f\"FineTune - Model: {model_name}_{FEATURE}, Task: {task_in}. Epoch: {epoch_num}, \"\n",
    "                f\"Strategy: {item}, \"\n",
    "                f\"TestScore: {test_score:>0.2f} at epoch {epoch}, \"\n",
    "                f\"ValScore: {score:>0.2f}, \"\n",
    "                f\"ValAccuracy: {acc:>0.2f}, \"\n",
    "                f\"ValLoss: {valloss:>0.2f}, \"\n",
    "                f\"IntraScore: {intra_score:>0.2f}, \"\n",
    "                f\"InterScore: {inter_score:>0.2f} \"\n",
    "            )\n",
    "            logger.info(log_msg)\n",
    "        print('')\n",
    "    \n",
    "    if save_model:\n",
    "        PATH = \"ckpts/FineTune-Models/{}_{}.pt\".format(model_name, task_in)\n",
    "        torch.save(best_dict, PATH)\n",
    "\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = [\"score\", \"accuracy\", \"loss\"]\n",
    "best_results = iteration('CNN', strategy, epoch_num = 100, num_iters = 1)\n",
    "print('\\nBest results of iters: ', best_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Back to List of Content](#list_of_content)\n",
    "\n",
    "<hr style=\"border:2px solid grey\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Evaluate Finetunned Model <a id=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGY = \"score\"\n",
    "MODEL = \"SupCon\"\n",
    "CLASSES = {\n",
    "    \"Task_11\": {0:'N', 1:'A'},\n",
    "    \"Task_12\": {0:'N', 1:'R', 2:'W', 3:'S', 4:'C', 5:'F', 6:'W&C'},\n",
    "    \"Task_21\": {0:'N', 1:'P', 2:'A'},\n",
    "    \"Task_22\": {0:'N', 1:'P', 2:'C', 3:'D', 4:'C&D'},\n",
    "}\n",
    "\n",
    "PRS_classifier,_,spike = get_model(MODEL)\n",
    "PATH = \"ckpts/FineTune-Models/{}_{}.pt\".format(MODEL, task_in)\n",
    "CheckPoint = torch.load(PATH)\n",
    "PRS_classifier.load_state_dict(\n",
    "    CheckPoint[STRATEGY][\"model_state_dict\"]\n",
    ")\n",
    "PRS_classifier.eval()\n",
    "print(\"PRS model is switched to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain Testing...\")\n",
    "\n",
    "train_score, truth, preds = test_model(\n",
    "    device=DEVICE,\n",
    "    task=main_task,\n",
    "    dataloader=dataloader[\"train\"],\n",
    "    trained_model=PRS_classifier,\n",
    "    verbose=True,\n",
    "    spike=spike\n",
    ")\n",
    "cm = confusion_matrix(y_true=truth, y_pred=preds)\n",
    "vs.plot_confusion_matrix(cm=cm, normalize=True, classes=CLASSES[task_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValid Testing...\")\n",
    "\n",
    "valid_score, truth, preds = test_model(\n",
    "    device=DEVICE,\n",
    "    task=main_task,\n",
    "    dataloader=dataloader[\"val\"],\n",
    "    trained_model=PRS_classifier,\n",
    "    verbose=True,\n",
    "    spike=spike\n",
    ")\n",
    "cm = confusion_matrix(y_true=truth, y_pred=preds)\n",
    "vs.plot_confusion_matrix(cm=cm, normalize=True, classes=CLASSES[task_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIntra Testing...\")\n",
    "    \n",
    "intra_score, truth, preds = test_model(\n",
    "    device=DEVICE,\n",
    "    task=main_task,\n",
    "    dataloader=intra_testloader,\n",
    "    trained_model=PRS_classifier,\n",
    "    verbose=True,\n",
    "    spike=spike\n",
    ")\n",
    "cm = confusion_matrix(y_true=truth, y_pred=preds)\n",
    "vs.plot_confusion_matrix(cm=cm, normalize=True, classes=CLASSES[task_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInter Testing...\")\n",
    "\n",
    "inter_score, truth, preds = test_model(\n",
    "    device=DEVICE,\n",
    "    task=main_task,\n",
    "    dataloader=inter_testloader,\n",
    "    trained_model=PRS_classifier,\n",
    "    verbose=True,\n",
    "    spike=spike\n",
    ")\n",
    "cm = confusion_matrix(y_true=truth, y_pred=preds)\n",
    "vs.plot_confusion_matrix(cm=cm, normalize=True, classes=CLASSES[task_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log results\n",
    "log_msg = (\n",
    "    f\"Testing - Model: {opt.model}_{FEATURE}, Task: {opt.task_in}, \"\n",
    "    f\"Train Score: {train_score:>0.2f}, \"\n",
    "    f\"Valid Score: {valid_score:>0.2f}, \"\n",
    "    f\"Intra Score: {intra_score:>0.2f}, \"\n",
    "    f\"Inter Score: {inter_score:>0.2f} at {opt.model_name}/{opt.ckpt} \"\n",
    ")\n",
    "logger.info(log_msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If decide to move into `models` folder please run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"ckpts/FineTune-Models/{}_{}.pt\".format(MODEL, task_in)\n",
    "mdls = torch.load(ckpt_path)\n",
    "save_path = \"models/{}/model.pt\".format(task_in[-2:])\n",
    "torch.save(mdls[\"score\"], save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
