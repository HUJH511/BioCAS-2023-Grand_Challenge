{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-test for analysing results from main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.data.dataloader as dl\n",
    "import src.utils.metric as customMetric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"Task_11\", \"Task_12\", \"Task_21\", \"Task_22\"]\n",
    "version = '/V5'\n",
    "out_path_11 = \"models\"+ version +\"/11/out.json\"\n",
    "out_path_12 = \"models\"+ version +\"/12/out.json\"\n",
    "out_path_21 = \"models\"+ version +\"/21/out.json\"\n",
    "out_path_22 = \"models\"+ version +\"/22/out.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_series_11 = pd.read_json(out_path_11, typ='series')\n",
    "out_series_12 = pd.read_json(out_path_12, typ='series')\n",
    "out_series_21 = pd.read_json(out_path_21, typ='series')\n",
    "out_series_22 = pd.read_json(out_path_22, typ='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_11 = pd.DataFrame({'audio': out_series_11.index, 'label':out_series_11.values})\n",
    "out_df_12 = pd.DataFrame({'audio': out_series_12.index, 'label':out_series_12.values})\n",
    "out_df_21 = pd.DataFrame({'audio': out_series_21.index, 'label':out_series_21.values})\n",
    "out_df_22 = pd.DataFrame({'audio': out_series_22.index, 'label':out_series_22.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_json_dir = \"SPRSound/test_json/inter_test_json\"\n",
    "intra_json_dir = \"SPRSound/test_json/intra_test_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genLabels(json_dir, task):\n",
    "    dataframe = pd.DataFrame(columns = [\"audio\", \"Task_{}1\".format(task), \"Task_{}2\".format(task)])\n",
    "    for recording in os.listdir(json_dir):\n",
    "            name = recording[:-5]\n",
    "            wav_name = name + \".wav\"\n",
    "            entry = name.split(\"_\")\n",
    "            patiend_id = int(entry[0])\n",
    "            age = float(entry[1])\n",
    "            gender = int(entry[2])\n",
    "            loc = int(entry[3][-1])\n",
    "            rec_id = int(entry[4])\n",
    "            with open(os.path.join(json_dir, recording)) as f:\n",
    "                rec_json = json.load(f)\n",
    "            if task == 1:\n",
    "                events = rec_json[\"event_annotation\"]\n",
    "                clip_prs = []\n",
    "                count = 0\n",
    "                for i, event in enumerate(events):\n",
    "                    label_12 = event[\"type\"].replace(\"+\", \"&\")\n",
    "                    label_11 = \"Adventitious\" if label_12 != \"Normal\" else label_12\n",
    "                    new_row = pd.DataFrame({\"audio\": name+\"_{}.wav\".format(count), \"Task_11\": label_11, \"Task_12\":label_12}, index=[0])\n",
    "                    dataframe = pd.concat([dataframe.loc[:], new_row]).reset_index(drop=True)\n",
    "                    count = count + 1 \n",
    "                    \n",
    "            elif task == 2:\n",
    "                label_22 = rec_json[\"record_annotation\"]\n",
    "                label_21 = (\n",
    "                    \"Adventitious\"\n",
    "                    if label_22 not in (\"Normal\", \"Poor Quality\")\n",
    "                    else label_22\n",
    "                )\n",
    "                new_row = pd.DataFrame({\"audio\": name+\".wav\", \"Task_21\": label_21, \"Task_22\":label_22}, index=[0])\n",
    "                dataframe = pd.concat([dataframe.loc[:], new_row]).reset_index(drop=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_intertest_1 = genLabels(inter_json_dir, 1)\n",
    "label_intertest_2 = genLabels(intra_json_dir, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate analysis for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_11_df = label_intertest_1.join(out_df_11.set_index('audio'), \n",
    "                                    on='audio').drop(\"Task_12\", axis=1)\n",
    "task_11_df[\"Task_11\"] = task_11_df[\"Task_11\"].apply(lambda x: (dl.label2idx(x, \"Task_11\")).cpu().detach().numpy())\n",
    "task_11_df[\"label\"] = task_11_df[\"label\"].apply(lambda x: (dl.label2idx(x, \"Task_11\")).cpu().detach().numpy()) \n",
    "task_11_df[\"match\"] = np.where(task_11_df[\"Task_11\"]==task_11_df[\"label\"], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_12_df = label_intertest_1.join(out_df_12.set_index('audio'), \n",
    "                                    on='audio').drop(\"Task_11\", axis=1)\n",
    "task_12_df[\"Task_12\"] = task_12_df[\"Task_12\"].apply(lambda x: (dl.label2idx(x, \"Task_12\")).cpu().detach().numpy())\n",
    "task_12_df[\"label\"] = task_12_df[\"label\"].apply(lambda x: (dl.label2idx(x, \"Task_12\")).cpu().detach().numpy()) \n",
    "task_12_df[\"match\"] = np.where(task_12_df[\"Task_12\"]==task_12_df[\"label\"], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (SE): 0.9203\n",
      "Specificity (SP): 0.8923\n",
      "Average Score (AS): 0.9063\n",
      "Harmonic Score (HS): 0.9061\n",
      "Score: 0.9062\n",
      "Sensitivity (SE): 0.7481\n",
      "Specificity (SP): 0.8856\n",
      "Average Score (AS): 0.8168\n",
      "Harmonic Score (HS): 0.8110\n",
      "Score: 0.8139\n"
     ]
    }
   ],
   "source": [
    "score_11 = customMetric.calc_score(task_11_df[\"Task_11\"], task_11_df[\"label\"], True, 1)\n",
    "score_12 = customMetric.calc_score(task_12_df[\"Task_12\"], task_12_df[\"label\"], True, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Analysis for Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_21_df = label_intertest_2.join(out_df_21.set_index('audio'), \n",
    "                                    on='audio').drop(\"Task_22\", axis=1)\n",
    "task_21_df[\"Task_21\"] = task_21_df[\"Task_21\"].apply(lambda x: (dl.label2idx(x, \"Task_21\")).cpu().detach().numpy())\n",
    "task_21_df[\"label\"] = task_21_df[\"label\"].apply(lambda x: (dl.label2idx(x, \"Task_21\")).cpu().detach().numpy()) \n",
    "task_21_df[\"match\"] = np.where(task_21_df[\"Task_21\"]==task_21_df[\"label\"], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_22_df = label_intertest_2.join(out_df_22.set_index('audio'), \n",
    "                                    on='audio').drop(\"Task_21\", axis=1)\n",
    "task_22_df[\"Task_22\"] = task_22_df[\"Task_22\"].apply(lambda x: (dl.label2idx(x, \"Task_22\")).cpu().detach().numpy())\n",
    "task_22_df[\"label\"] = task_22_df[\"label\"].apply(lambda x: (dl.label2idx(x, \"Task_22\")).cpu().detach().numpy()) \n",
    "task_22_df[\"match\"] = np.where(task_22_df[\"Task_22\"]==task_22_df[\"label\"], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (SE): 0.9338\n",
      "Specificity (SP): 0.9419\n",
      "Average Score (AS): 0.9379\n",
      "Harmonic Score (HS): 0.9378\n",
      "Score: 0.9379\n",
      "Sensitivity (SE): 0.8676\n",
      "Specificity (SP): 0.9212\n",
      "Average Score (AS): 0.8944\n",
      "Harmonic Score (HS): 0.8936\n",
      "Score: 0.8940\n"
     ]
    }
   ],
   "source": [
    "score_21 = customMetric.calc_score(task_21_df[\"Task_21\"], task_21_df[\"label\"], True, 2)\n",
    "score_22 = customMetric.calc_score(task_22_df[\"Task_22\"], task_22_df[\"label\"], True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECGJH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
